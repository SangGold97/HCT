{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sksurv.metrics import concordance_index_censored\n",
    "import bisect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "X = data.drop(['efs_time', 'efs'], axis=1) \n",
    "y_time = data['efs_time']\n",
    "y_event = data['efs']\n",
    "\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# X[numerical_cols] = X[numerical_cols].fillna(X[numerical_cols].mean())\n",
    "# X[categorical_cols] = X[categorical_cols].fillna(X[categorical_cols].mode().iloc[0])\n",
    "# le_dict = {}\n",
    "# for col in categorical_cols:\n",
    "#     le = LabelEncoder()\n",
    "#     X[col] = le.fit_transform(X[col])\n",
    "#     le_dict[col] = le\n",
    "\n",
    "# Handle categorical columns\n",
    "for col in categorical_cols:\n",
    "    X[col] = X[col].astype('object')\n",
    "    value_counts = X[col].value_counts()\n",
    "    category_map = {cat: idx for idx, cat in enumerate(value_counts.index)}\n",
    "    X[col] = X[col].map(category_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>dri_score</th>\n",
       "      <th>psych_disturb</th>\n",
       "      <th>cyto_score</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>hla_match_c_high</th>\n",
       "      <th>hla_high_res_8</th>\n",
       "      <th>tbi_status</th>\n",
       "      <th>arrhythmia</th>\n",
       "      <th>hla_low_res_6</th>\n",
       "      <th>...</th>\n",
       "      <th>karnofsky_score</th>\n",
       "      <th>hepatic_mild</th>\n",
       "      <th>tce_div_match</th>\n",
       "      <th>donor_related</th>\n",
       "      <th>melphalan_dose</th>\n",
       "      <th>hla_low_res_8</th>\n",
       "      <th>cardiac</th>\n",
       "      <th>hla_match_drb1_high</th>\n",
       "      <th>pulm_moderate</th>\n",
       "      <th>hla_low_res_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28795</th>\n",
       "      <td>28795</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28796</th>\n",
       "      <td>28796</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28797</th>\n",
       "      <td>28797</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28798</th>\n",
       "      <td>28798</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28799</th>\n",
       "      <td>28799</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28800 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  dri_score  psych_disturb  cyto_score  diabetes  \\\n",
       "0          0        3.0            0.0         NaN       0.0   \n",
       "1          1        0.0            0.0         1.0       0.0   \n",
       "2          2        3.0            0.0         NaN       0.0   \n",
       "3          3        2.0            0.0         1.0       0.0   \n",
       "4          4        2.0            0.0         NaN       0.0   \n",
       "...      ...        ...            ...         ...       ...   \n",
       "28795  28795        7.0            NaN         2.0       0.0   \n",
       "28796  28796        2.0            0.0         0.0       1.0   \n",
       "28797  28797        4.0            NaN         0.0       NaN   \n",
       "28798  28798        3.0            0.0         0.0       0.0   \n",
       "28799  28799        1.0            0.0         NaN       0.0   \n",
       "\n",
       "       hla_match_c_high  hla_high_res_8  tbi_status  arrhythmia  \\\n",
       "0                   NaN             NaN           0         0.0   \n",
       "1                   2.0             8.0           3         0.0   \n",
       "2                   2.0             8.0           0         0.0   \n",
       "3                   2.0             8.0           0         0.0   \n",
       "4                   2.0             8.0           0         0.0   \n",
       "...                 ...             ...         ...         ...   \n",
       "28795               2.0             8.0           0         0.0   \n",
       "28796               1.0             4.0           0         0.0   \n",
       "28797               2.0             8.0           0         NaN   \n",
       "28798               1.0             4.0           0         0.0   \n",
       "28799               2.0             8.0           0         0.0   \n",
       "\n",
       "       hla_low_res_6  ...  karnofsky_score  hepatic_mild  tce_div_match  \\\n",
       "0                6.0  ...             90.0           0.0            NaN   \n",
       "1                6.0  ...             90.0           0.0            0.0   \n",
       "2                6.0  ...             90.0           0.0            0.0   \n",
       "3                6.0  ...             90.0           1.0            0.0   \n",
       "4                6.0  ...             90.0           0.0            0.0   \n",
       "...              ...  ...              ...           ...            ...   \n",
       "28795            6.0  ...              NaN           NaN            3.0   \n",
       "28796            5.0  ...             90.0           0.0            1.0   \n",
       "28797            6.0  ...             90.0           NaN            1.0   \n",
       "28798            3.0  ...             90.0           0.0            0.0   \n",
       "28799            6.0  ...             90.0           0.0            0.0   \n",
       "\n",
       "       donor_related  melphalan_dose  hla_low_res_8  cardiac  \\\n",
       "0                1.0             0.0            8.0      0.0   \n",
       "1                0.0             0.0            8.0      0.0   \n",
       "2                0.0             0.0            8.0      0.0   \n",
       "3                1.0             0.0            8.0      0.0   \n",
       "4                0.0             1.0            8.0      0.0   \n",
       "...              ...             ...            ...      ...   \n",
       "28795            NaN             0.0            8.0      NaN   \n",
       "28796            0.0             0.0            6.0      1.0   \n",
       "28797            1.0             0.0            8.0      NaN   \n",
       "28798            0.0             1.0            4.0      0.0   \n",
       "28799            0.0             1.0            8.0      0.0   \n",
       "\n",
       "       hla_match_drb1_high  pulm_moderate  hla_low_res_10  \n",
       "0                      2.0            0.0            10.0  \n",
       "1                      2.0            1.0            10.0  \n",
       "2                      2.0            0.0            10.0  \n",
       "3                      2.0            0.0            10.0  \n",
       "4                      2.0            0.0            10.0  \n",
       "...                    ...            ...             ...  \n",
       "28795                  2.0            0.0            10.0  \n",
       "28796                  1.0            1.0             8.0  \n",
       "28797                  2.0            0.0            10.0  \n",
       "28798                  1.0            0.0             5.0  \n",
       "28799                  2.0            1.0            10.0  \n",
       "\n",
       "[28800 rows x 58 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoxObjective:\n",
    "    def __init__(self, time, event):\n",
    "        self.time = time\n",
    "        self.event = event\n",
    "        self.sorted_indices = np.argsort(self.time)\n",
    "        self.sorted_time = self.time[self.sorted_indices]\n",
    "        self.sorted_event = self.event[self.sorted_indices]\n",
    "        self.event_positions_sorted = [i for i in range(len(self.sorted_event)) if self.sorted_event[i] == 1]\n",
    "\n",
    "    def __call__(self, y_pred, dataset=None):  # Added dataset parameter with default None\n",
    "        sorted_exp_f = np.exp(y_pred[self.sorted_indices])\n",
    "        sum_risk = np.cumsum(sorted_exp_f[::-1])[::-1]\n",
    "        \n",
    "        sum_1_over_sum_risk = []\n",
    "        sum_1_over_sum_risk_squared = []\n",
    "        for event_pos in self.event_positions_sorted:\n",
    "            sum_r = sum_risk[event_pos]\n",
    "            sum_1_over_sum_risk.append(1 / sum_r)\n",
    "            sum_1_over_sum_risk_squared.append(1 / sum_r**2)\n",
    "        \n",
    "        cum_sum_1_over_sum_risk = np.cumsum(sum_1_over_sum_risk)\n",
    "        cum_sum_1_over_sum_risk_squared = np.cumsum(sum_1_over_sum_risk_squared)\n",
    "        \n",
    "        gradients = np.zeros(len(y_pred))\n",
    "        hessians = np.zeros(len(y_pred))\n",
    "        sorted_position = {self.sorted_indices[k]: k for k in range(len(self.sorted_indices))}\n",
    "        \n",
    "        for k in range(len(y_pred)):\n",
    "            sorted_pos_k = sorted_position[k]\n",
    "            index = bisect.bisect_right(self.event_positions_sorted, sorted_pos_k)\n",
    "            sum_1_over_sum_risk_k = cum_sum_1_over_sum_risk[index-1] if index > 0 else 0\n",
    "            sum_1_over_sum_risk_squared_k = cum_sum_1_over_sum_risk_squared[index-1] if index > 0 else 0\n",
    "            \n",
    "            exp_f_k = np.exp(y_pred[k])\n",
    "            sum_term_grad = exp_f_k * sum_1_over_sum_risk_k\n",
    "            sum_term_hess = exp_f_k * sum_1_over_sum_risk_k - exp_f_k**2 * sum_1_over_sum_risk_squared_k\n",
    "            \n",
    "            gradient_k = - self.event[k] + sum_term_grad\n",
    "            hessian_k = sum_term_hess\n",
    "            \n",
    "            gradients[k] = gradient_k\n",
    "            hessians[k] = hessian_k\n",
    "            \n",
    "        return gradients, hessians\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    params = {\n",
    "        'metric': 'custom',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 25, 127),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-06, 10., log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-06, 10., log=True),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 100),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.7, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.7, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
    "        'verbose': -1,\n",
    "        'num_threads': 4,\n",
    "        'seed': 42\n",
    "    }\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    race_groups = X['race_group'].unique()\n",
    "    fold_scores = []\n",
    "    fold = -1\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X, X['race_group']):\n",
    "        fold += 1\n",
    "        print(f'Running in fold {fold}...')\n",
    "        \n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_time_train, y_time_val = y_time.iloc[train_idx], y_time.iloc[val_idx]\n",
    "        y_event_train, y_event_val = y_event.iloc[train_idx], y_event.iloc[val_idx]\n",
    "\n",
    "        train_data = lgb.Dataset(X_train, label= y_time_train)\n",
    "        val_data = lgb.Dataset(X_val, label= y_time_val)\n",
    "\n",
    "        def cindex_eval(y_pred, data_val):\n",
    "            # Calculate stratified C-index for validation data\n",
    "            race_specific_scores = []\n",
    "            for race in race_groups:\n",
    "                race_mask = X_val['race_group'] == race\n",
    "                if sum(race_mask) > 1:  # Only calculate if we have at least 2 samples\n",
    "                    surv = np.array([(e, t) for e, t in zip(y_event_val[race_mask], y_time_val[race_mask])], \n",
    "                                dtype=[('event', bool), ('time', float)])\n",
    "                    race_cindex = concordance_index_censored(surv['event'], surv['time'], y_pred[race_mask])[0]\n",
    "                    race_specific_scores.append(race_cindex)\n",
    "            \n",
    "            stratified_cindex = np.mean(race_specific_scores) - np.std(race_specific_scores)\n",
    "            return 'stratified-c-index', stratified_cindex, True\n",
    "        \n",
    "        params['objective'] = CoxObjective(y_time_train.values, y_event_train.values)\n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_data,\n",
    "            valid_sets=[val_data],\n",
    "            num_boost_round=1000,\n",
    "            feval=cindex_eval,\n",
    "            callbacks=[lgb.early_stopping(stopping_rounds=100)]\n",
    "        )\n",
    "        y_pred = model.predict(X_val)\n",
    "        \n",
    "        # Calculate stratified C-index for fold evaluation\n",
    "        stratified_cindex = cindex_eval(y_pred, X_val)[1]\n",
    "        fold_scores.append(stratified_cindex)\n",
    "    \n",
    "    print('5 folds stratified C-index:', fold_scores)\n",
    "    return np.mean(fold_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-23 11:27:55,795] A new study created in memory with name: no-name-ac56b860-0188-43dc-8d5a-7ef244c0cbe2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in fold 0...\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[981]\tvalid_0's stratified-c-index: 0.670308\n",
      "Running in fold 1...\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's stratified-c-index: 0.665402\n",
      "Running in fold 2...\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[663]\tvalid_0's stratified-c-index: 0.67158\n",
      "Running in fold 3...\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[996]\tvalid_0's stratified-c-index: 0.666663\n",
      "Running in fold 4...\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-23 11:39:07,378] Trial 0 finished with value: 0.6691694459688596 and parameters: {'num_leaves': 83, 'max_depth': 3, 'learning_rate': 0.04359342334700091, 'reg_alpha': 0.1036044609448446, 'reg_lambda': 0.01075941481680774, 'min_data_in_leaf': 34, 'feature_fraction': 0.9589439313386453, 'bagging_fraction': 0.9146803705656553, 'bagging_freq': 8}. Best is trial 0 with value: 0.6691694459688596.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[984]\tvalid_0's stratified-c-index: 0.671893\n",
      "5 folds stratified C-index: [0.6703083210658878, 0.6654016322438691, 0.6715804759564039, 0.6666633419249612, 0.6718934586531767]\n",
      "Running in fold 0...\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[425]\tvalid_0's stratified-c-index: 0.669396\n",
      "Running in fold 1...\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[189]\tvalid_0's stratified-c-index: 0.667031\n",
      "Running in fold 2...\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[319]\tvalid_0's stratified-c-index: 0.673375\n",
      "Running in fold 3...\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[336]\tvalid_0's stratified-c-index: 0.667561\n",
      "Running in fold 4...\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-23 11:43:48,415] Trial 1 finished with value: 0.6700832413326882 and parameters: {'num_leaves': 107, 'max_depth': 8, 'learning_rate': 0.07896707223646482, 'reg_alpha': 0.11605080518387101, 'reg_lambda': 0.025076792784528377, 'min_data_in_leaf': 68, 'feature_fraction': 0.781785417207505, 'bagging_fraction': 0.7804909992546571, 'bagging_freq': 1}. Best is trial 1 with value: 0.6700832413326882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[202]\tvalid_0's stratified-c-index: 0.673053\n",
      "5 folds stratified C-index: [0.6693963669309454, 0.6670308445651525, 0.6733750811215895, 0.6675610939666392, 0.6730528200791138]\n",
      "Running in fold 0...\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[208]\tvalid_0's stratified-c-index: 0.667505\n",
      "Running in fold 1...\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[171]\tvalid_0's stratified-c-index: 0.660858\n",
      "Running in fold 2...\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[104]\tvalid_0's stratified-c-index: 0.664182\n",
      "Running in fold 3...\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[289]\tvalid_0's stratified-c-index: 0.670135\n",
      "Running in fold 4...\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-23 11:47:09,188] Trial 2 finished with value: 0.6663032527510737 and parameters: {'num_leaves': 94, 'max_depth': 7, 'learning_rate': 0.09084202254308012, 'reg_alpha': 0.0014596453525443948, 'reg_lambda': 0.00024462999665005535, 'min_data_in_leaf': 44, 'feature_fraction': 0.8091222611702042, 'bagging_fraction': 0.7009881182151815, 'bagging_freq': 4}. Best is trial 1 with value: 0.6700832413326882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[142]\tvalid_0's stratified-c-index: 0.668835\n",
      "5 folds stratified C-index: [0.6675051784323076, 0.6608581406165336, 0.6641824738224218, 0.6701354387564878, 0.6688350321276174]\n"
     ]
    }
   ],
   "source": [
    "# Now create and run the study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=3, n_jobs=1)\n",
    "best_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['dri_score', 'psych_disturb', 'cyto_score', 'diabetes', 'tbi_status',\\n       'arrhythmia', 'graft_type', 'vent_hist', 'renal_issue', 'pulm_severe',\\n       'prim_disease_hct', 'cmv_status', 'tce_imm_match', 'rituximab',\\n       'prod_type', 'cyto_score_detail', 'conditioning_intensity', 'ethnicity',\\n       'obesity', 'mrd_hct', 'in_vivo_tcd', 'tce_match', 'hepatic_severe',\\n       'prior_tumor', 'peptic_ulcer', 'gvhd_proph', 'rheum_issue', 'sex_match',\\n       'race_group', 'hepatic_mild', 'tce_div_match', 'donor_related',\\n       'melphalan_dose', 'cardiac', 'pulm_moderate'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m X[numerical_cols] \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(X[numerical_cols])\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Convert categorical features to one-hot encoding\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dummies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_cols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Get race_group from original data for stratification\u001b[39;00m\n\u001b[1;32m     17\u001b[0m original_race_groups \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrace_group\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/hct/lib/python3.12/site-packages/pandas/core/reshape/encoding.py:169\u001b[0m, in \u001b[0;36mget_dummies\u001b[0;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput must be a list-like for parameter `columns`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     data_to_encode \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# validate prefixes and separator to avoid silently dropping cols\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcheck_len\u001b[39m(item, name: \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/hct/lib/python3.12/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/hct/lib/python3.12/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/hct/lib/python3.12/site-packages/pandas/core/indexes/base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[1;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[0;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['dri_score', 'psych_disturb', 'cyto_score', 'diabetes', 'tbi_status',\\n       'arrhythmia', 'graft_type', 'vent_hist', 'renal_issue', 'pulm_severe',\\n       'prim_disease_hct', 'cmv_status', 'tce_imm_match', 'rituximab',\\n       'prod_type', 'cyto_score_detail', 'conditioning_intensity', 'ethnicity',\\n       'obesity', 'mrd_hct', 'in_vivo_tcd', 'tce_match', 'hepatic_severe',\\n       'prior_tumor', 'peptic_ulcer', 'gvhd_proph', 'rheum_issue', 'sex_match',\\n       'race_group', 'hepatic_mild', 'tce_div_match', 'donor_related',\\n       'melphalan_dose', 'cardiac', 'pulm_moderate'],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for CoxPH\n",
    "import torch\n",
    "import torchtuples as tt\n",
    "from pycox.models import CoxPH\n",
    "from pycox.evaluation import EvalSurv\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Preprocess the data for CoxPH\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "X[numerical_cols] = scaler.fit_transform(X[numerical_cols])\n",
    "\n",
    "# Convert categorical features to one-hot encoding\n",
    "X = pd.get_dummies(X, columns=categorical_cols)\n",
    "\n",
    "# Split the data into training and validation sets using StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "race_groups = X['race_group'].unique()\n",
    "fold_scores = []\n",
    "\n",
    "for train_idx, val_idx in skf.split(X, X['race_group']):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_time_train, y_time_val = y_time.iloc[train_idx], y_time.iloc[val_idx]\n",
    "    y_event_train, y_event_val = y_event.iloc[train_idx], y_event.iloc[val_idx]\n",
    "\n",
    "    # Prepare the data for CoxPH\n",
    "    train = (X_train, y_time_train, y_event_train)\n",
    "    val = (X_val, y_time_val, y_event_val)\n",
    "\n",
    "    # Define the neural network structure\n",
    "    num_nodes = [32, 32]\n",
    "    batch_norm = True\n",
    "    dropout = 0.1\n",
    "    output_bias = False\n",
    "\n",
    "    net = tt.practical.MLPVanilla(X_train.shape[1], num_nodes, batch_norm, dropout, output_bias=output_bias)\n",
    "    model = CoxPH(net, tt.optim.Adam)\n",
    "\n",
    "    # Train the model\n",
    "    batch_size = 256\n",
    "    epochs = 100\n",
    "    callbacks = [tt.callbacks.EarlyStopping(patience=10)]\n",
    "    log = model.fit(X_train, (y_time_train, y_event_train), batch_size, epochs, callbacks, val_data=val, val_batch_size=batch_size)\n",
    "\n",
    "    # Predict survival function for validation data\n",
    "    surv = model.predict_surv_df(X_val)\n",
    "\n",
    "    # Evaluate the model using stratified C-index\n",
    "    race_specific_scores = []\n",
    "    for race in race_groups:\n",
    "        race_mask = X_val['race_group'] == race\n",
    "        if sum(race_mask) > 1:  # Only calculate if we have at least 2 samples\n",
    "            surv_race = surv.loc[:, race_mask]\n",
    "            ev = EvalSurv(surv_race, y_time_val[race_mask], y_event_val[race_mask], censor_surv='km')\n",
    "            race_cindex = ev.concordance_td('antolini')\n",
    "            race_specific_scores.append(race_cindex)\n",
    "\n",
    "    stratified_cindex = np.mean(race_specific_scores) - np.std(race_specific_scores)\n",
    "    fold_scores.append(stratified_cindex)\n",
    "\n",
    "print('5 folds stratified C-index:', fold_scores)\n",
    "print('Mean stratified C-index:', np.mean(fold_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
