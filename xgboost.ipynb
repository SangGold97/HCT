{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import xgboost as xgb\n",
    "from lifelines.utils import concordance_index\n",
    "import optuna\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "X = data.drop(['efs_time', 'efs', 'ID'], axis=1) \n",
    "y = data[['efs_time', 'efs']]\n",
    "\n",
    "# test data\n",
    "data_test = pd.read_csv('test.csv')\n",
    "X_test = data_test.drop(columns=['ID'], axis=1)\n",
    "\n",
    "def preprocess_data(df: pd.DataFrame):\n",
    "    numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "    for col in categorical_cols:\n",
    "        value_counts = df[col].value_counts()\n",
    "        category_map = {cat: idx for idx, cat in enumerate(value_counts.index)}\n",
    "        df[col] = df[col].map(category_map)\n",
    "        df[col] = df[col].astype('category')\n",
    "    \n",
    "    df['year_hct'] = df['year_hct'] - 2000\n",
    "    return df\n",
    "\n",
    "X = preprocess_data(X)\n",
    "X_test = preprocess_data(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    param = {\n",
    "        'objective': 'survival:aft',\n",
    "        # 'eval_metric': 'aft-nloglik',\n",
    "        'tree_method': 'hist',\n",
    "        'lambda': trial.suggest_float('lambda', 1e-6, 10.0, log=True),\n",
    "        'alpha': trial.suggest_float('alpha', 1e-6, 10.0, log=True),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-2, 0.1),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.8, 1.0),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.8, 1.0),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'random_state': 42,\n",
    "        'verbosity': 0\n",
    "    }\n",
    "    \n",
    "    X_val_5folds = pd.DataFrame([], columns=X.columns)\n",
    "    y_val_5folds = pd.DataFrame([], columns=y.columns)   \n",
    "    y_pred_5folds = []\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
    "    for train_index, val_index in skf.split(X, X['race_group']):\n",
    "        X_tr, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_tr, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "        \n",
    "        # Create lower and upper bounds for AFT model\n",
    "        lower_bounds = y_tr['efs_time'].values  # Lower bound is observed time for all\n",
    "        \n",
    "        # For upper bound: same as observed time for events, infinity for censored\n",
    "        upper_bounds = y_tr['efs_time'].values.copy()\n",
    "        upper_bounds[y_tr['efs'] == 0] = float('inf')  # Set censored observations to infinity\n",
    "        \n",
    "        # Create validation bounds too\n",
    "        val_lower_bounds = y_val['efs_time'].values\n",
    "        val_upper_bounds = y_val['efs_time'].values.copy()\n",
    "        val_upper_bounds[y_val['efs'] == 0] = float('inf')\n",
    "        \n",
    "        # Create DMatrix with proper label bounds\n",
    "        dtrain = xgb.DMatrix(\n",
    "            X_tr, \n",
    "            label=y_tr['efs_time'],\n",
    "            enable_categorical=True,\n",
    "            feature_weights=None,\n",
    "            label_lower_bound=lower_bounds,\n",
    "            label_upper_bound=upper_bounds\n",
    "        )\n",
    "        \n",
    "        dval = xgb.DMatrix(\n",
    "            X_val, \n",
    "            label=y_val['efs_time'], \n",
    "            enable_categorical=True,\n",
    "            feature_weights=None,\n",
    "            label_lower_bound=val_lower_bounds,\n",
    "            label_upper_bound=val_upper_bounds\n",
    "        )\n",
    "        \n",
    "        model = xgb.train(\n",
    "            param, \n",
    "            dtrain, \n",
    "            evals=[(dval, 'eval')], \n",
    "            num_boost_round=1000,\n",
    "            early_stopping_rounds=100, \n",
    "            verbose_eval=False\n",
    "        )\n",
    "\n",
    "        X_val_5folds = pd.concat([X_val_5folds, X_val], axis=0, ignore_index=True)\n",
    "        y_val_5folds = pd.concat([y_val_5folds, y_val], axis=0, ignore_index=True)\n",
    "        preds = model.predict(dval)\n",
    "        y_pred_5folds += list(preds)\n",
    "\n",
    "    race_groups = X_val_5folds['race_group'].unique()\n",
    "    c_index_scores_by_race = []\n",
    "    for race in race_groups:\n",
    "        race_mask = X_val_5folds['race_group'] == race\n",
    "        c_index_race = concordance_index(\n",
    "            y_val_5folds['efs_time'][race_mask], \n",
    "            np.array(y_pred_5folds)[race_mask], \n",
    "            y_val_5folds['efs'][race_mask]\n",
    "        )\n",
    "        c_index_scores_by_race.append(c_index_race)\n",
    "\n",
    "    return np.mean(c_index_scores_by_race) - np.sqrt(np.var(c_index_scores_by_race))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-27 14:35:53,674] A new study created in memory with name: no-name-79ff1882-e228-4012-a16a-012261e80618\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a016d27837746e88b14a248d80b634a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-02-27 14:35:56,696] Trial 0 finished with value: 0.6649324128038797 and parameters: {'lambda': 0.0008583933121248923, 'alpha': 2.6655344100412997, 'learning_rate': 0.098400465628949, 'subsample': 0.9184946812328655, 'colsample_bytree': 0.9878581857773272, 'max_depth': 4, 'min_child_weight': 8}. Best is trial 0 with value: 0.6649324128038797.\n",
      "[I 2025-02-27 14:36:05,186] Trial 1 finished with value: 0.6647546032694026 and parameters: {'lambda': 1.5702965989264461, 'alpha': 0.007953893879969672, 'learning_rate': 0.02557106160030199, 'subsample': 0.9348231222585843, 'colsample_bytree': 0.8999920032919763, 'max_depth': 6, 'min_child_weight': 3}. Best is trial 0 with value: 0.6649324128038797.\n",
      "[I 2025-02-27 14:36:08,575] Trial 2 finished with value: 0.6627480190355703 and parameters: {'lambda': 0.21078566223939313, 'alpha': 0.027667958495350357, 'learning_rate': 0.06795783245395481, 'subsample': 0.9156206571980972, 'colsample_bytree': 0.8886727617944985, 'max_depth': 6, 'min_child_weight': 10}. Best is trial 0 with value: 0.6649324128038797.\n",
      "Best hyperparameters: {'lambda': 0.0008583933121248923, 'alpha': 2.6655344100412997, 'learning_rate': 0.098400465628949, 'subsample': 0.9184946812328655, 'colsample_bytree': 0.9878581857773272, 'max_depth': 4, 'min_child_weight': 8}\n",
      "Best C-index: 0.6649324128038797\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=3, n_jobs=1,\n",
    "               show_progress_bar=True)\n",
    "\n",
    "print('Best hyperparameters:', study.best_params)\n",
    "print('Best C-index:', study.best_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vgp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
